{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **ğŸ“Œ Feature Scaling Explained in Simple Terms**\n",
    "\n",
    "Feature scaling is a technique to make sure different features (variables) in a dataset have similar ranges. Without scaling, one feature could have values in the thousands while another has values between 0 and 5, making it difficult for machine learning models to perform well.\n",
    "\n",
    "ğŸ’¡ **Why is Feature Scaling Important?**  \n",
    "Imagine you have two features:\n",
    "\n",
    "- **House Size (sq ft)** ğŸ  â†’ ranges from **300 to 2000**\n",
    "- **Number of Bedrooms** ğŸ›ï¸ â†’ ranges from **0 to 5**\n",
    "\n",
    "Since these two have very different numerical ranges, machine learning algorithms might give more importance to one over the other. Feature scaling fixes this!\n",
    "\n",
    "<div style=\"text-align:center;\">\n",
    "    <img src=\"https://user-images.githubusercontent.com/7065401/52071924-c003ad80-2562-11e9-8297-1c6595f8a7ff.png\" alt=\"green-divider\">\n",
    "</div>\n",
    "\n",
    "#### **ğŸ”¢ Different Methods of Feature Scaling**\n",
    "\n",
    "There are three popular methods of feature scaling:\n",
    "\n",
    "##### **1ï¸âƒ£ Min-Max Scaling (Normalization)**\n",
    "\n",
    "ğŸ‘‰ This method rescales the values to a fixed range **[0,1]**.  \n",
    "ğŸ‘‰ We divide each value by the maximum value of the feature.\n",
    "\n",
    "ğŸ”¹ **Formula:**\n",
    "\n",
    "$$\n",
    "x' = \\frac{x}{\\max(x)}\n",
    "$$\n",
    "\n",
    "ğŸ”¹ **Example:**  \n",
    "If **House Size** varies from **300 to 2000**:\n",
    "\n",
    "$$\n",
    "x' = \\frac{x}{2000}\n",
    "$$\n",
    "\n",
    "So, if the house size is **600**, the scaled value will be:\n",
    "\n",
    "$$\n",
    "\\frac{600}{2000} = 0.3\n",
    "$$\n",
    "\n",
    "If **Bedrooms** range from **0 to 5**:\n",
    "\n",
    "$$\n",
    "x' = \\frac{x}{5}\n",
    "$$\n",
    "\n",
    "So, if the number of bedrooms is **3**, the scaled value will be:\n",
    "\n",
    "$$\n",
    "\\frac{3}{5} = 0.6\n",
    "$$\n",
    "\n",
    "ğŸ“Œ **After scaling, all features are between 0 and 1!**\n",
    "\n",
    "<div style=\"text-align:center;\">\n",
    "    <img src=\"https://user-images.githubusercontent.com/7065401/52071924-c003ad80-2562-11e9-8297-1c6595f8a7ff.png\" alt=\"green-divider\">\n",
    "</div>\n",
    "\n",
    "##### **2ï¸âƒ£ Mean Normalization**\n",
    "\n",
    "ğŸ‘‰ This method centers the data around **0** (some values become negative, some positive).  \n",
    "ğŸ‘‰ Each value is adjusted by subtracting the mean and dividing by the range (max - min).\n",
    "\n",
    "ğŸ”¹ **Formula:**\n",
    "\n",
    "$$\n",
    "x' = \\frac{x - \\mu}{\\max(x) - \\min(x)}\n",
    "$$\n",
    "\n",
    "where **$ \\mu $** is the mean of the feature.\n",
    "\n",
    "ğŸ”¹ **Example:**  \n",
    "If **House Size** has:\n",
    "\n",
    "- Mean **$ \\mu_1 = 600 $**\n",
    "- Max = **2000**\n",
    "- Min = **300**\n",
    "\n",
    "Then, for a house size of **600**:\n",
    "\n",
    "$$\n",
    "x' = \\frac{600 - 600}{2000 - 300} = \\frac{0}{1700} = 0\n",
    "$$\n",
    "\n",
    "For **Bedrooms**, if:\n",
    "\n",
    "- Mean **$ \\mu_2 = 2.3 $**\n",
    "- Max = **5**\n",
    "- Min = **0**\n",
    "\n",
    "For 3 bedrooms:\n",
    "\n",
    "$$\n",
    "x' = \\frac{3 - 2.3}{5 - 0} = \\frac{0.7}{5} = 0.14\n",
    "$$\n",
    "\n",
    "ğŸ“Œ **After scaling, values are centered around 0!**\n",
    "\n",
    "<div style=\"text-align:center;\">\n",
    "    <img src=\"https://user-images.githubusercontent.com/7065401/52071924-c003ad80-2562-11e9-8297-1c6595f8a7ff.png\" alt=\"green-divider\">\n",
    "</div>\n",
    "\n",
    "##### **3ï¸âƒ£ Z-Score Normalization (Standardization)**\n",
    "\n",
    "ğŸ‘‰ This method transforms data to have **zero mean (0) and unit variance (1)**.  \n",
    "ğŸ‘‰ Useful when data follows a **normal distribution (bell-shaped curve)**.\n",
    "\n",
    "ğŸ”¹ **Formula:**\n",
    "\n",
    "$$\n",
    "x' = \\frac{x - \\mu}{\\sigma}\n",
    "$$\n",
    "\n",
    "where **$ \\sigma $** is the standard deviation of the feature.\n",
    "\n",
    "ğŸ”¹ **Example:**  \n",
    "If **House Size** has:\n",
    "\n",
    "- Mean **$ \\mu_1 = 600 $**\n",
    "- Standard deviation **$ \\sigma_1 = 450 $**\n",
    "\n",
    "Then, for a house size of **600**:\n",
    "\n",
    "$$\n",
    "x' = \\frac{600 - 600}{450} = 0\n",
    "$$\n",
    "\n",
    "For **Bedrooms**, if:\n",
    "\n",
    "- Mean **$ \\mu_2 = 2.3 $**\n",
    "- Standard deviation **$ \\sigma_2 = 1.4 $**\n",
    "\n",
    "For 3 bedrooms:\n",
    "\n",
    "$$\n",
    "x' = \\frac{3 - 2.3}{1.4} = 0.5\n",
    "$$\n",
    "\n",
    "ğŸ“Œ **After scaling, most values will be between -3 and 3!**\n",
    "\n",
    "<div style=\"text-align:center;\">\n",
    "    <img src=\"https://user-images.githubusercontent.com/7065401/52071924-c003ad80-2562-11e9-8297-1c6595f8a7ff.png\" alt=\"green-divider\">\n",
    "</div>\n",
    "\n",
    "#### **ğŸ› ï¸ When Should You Use Feature Scaling?**\n",
    "\n",
    "- âœ… If your dataset has **features with very different ranges**, scaling helps.\n",
    "- âœ… If you are using **gradient descent**, scaling speeds up learning.\n",
    "- âŒ If you're using **tree-based models (like Decision Trees, Random Forests)**, scaling is **not necessary**.\n",
    "\n",
    "##### **ğŸ¤” Quick Tips**\n",
    "\n",
    "âœ”ï¸ Features should generally be in the range **[-1,1]** or **[-3,3]**.  \n",
    "âœ”ï¸ If a feature has very **small values (0.001)** or **very large values (1000)**, **you must scale it**.  \n",
    "âœ”ï¸ **When in doubt, always scale!**\n",
    "\n",
    "---\n",
    "\n",
    "### **ğŸ“œ Summary**\n",
    "\n",
    "âœ… **Feature Scaling** ensures all features have similar ranges, improving machine learning performance.  \n",
    "âœ… Three common methods are:\n",
    "\n",
    "- **Min-Max Scaling (0-1 range)**\n",
    "- **Mean Normalization (centered at 0)**\n",
    "- **Z-Score Normalization (standardized with mean 0 and variance 1)**  \n",
    "  âœ… Feature scaling is crucial for **gradient descent** and models sensitive to feature magnitude.\n",
    "\n",
    "---\n",
    "\n",
    "#### **ğŸ“š Interactive Notes (MCQs)**\n",
    "\n",
    "##### **Question 1:** What is the main purpose of feature scaling?\n",
    "\n",
    "A) Make all features equal to 1  \n",
    "B) Speed up gradient descent and improve performance  \n",
    "C) Reduce the number of features  \n",
    "D) Remove unnecessary data\n",
    "\n",
    "##### **Question 2:** What is the range of values after Min-Max Scaling?\n",
    "\n",
    "A) -1 to 1  \n",
    "B) 0 to 1  \n",
    "C) -3 to 3  \n",
    "D) None of the above\n",
    "\n",
    "##### **Question 3:** Which method centers the data around zero?\n",
    "\n",
    "A) Min-Max Scaling  \n",
    "B) Mean Normalization  \n",
    "C) Z-Score Normalization  \n",
    "D) Both B & C\n",
    "\n",
    "##### **Question 4:** Which scaling method is best when the data follows a normal distribution?\n",
    "\n",
    "A) Min-Max Scaling  \n",
    "B) Mean Normalization  \n",
    "C) Z-Score Normalization  \n",
    "D) None of the above\n",
    "\n",
    "#### **ğŸ“Œ Answers:**\n",
    "\n",
    "1ï¸âƒ£ **B**  \n",
    "2ï¸âƒ£ **B**  \n",
    "3ï¸âƒ£ **D**  \n",
    "4ï¸âƒ£ **C**\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
