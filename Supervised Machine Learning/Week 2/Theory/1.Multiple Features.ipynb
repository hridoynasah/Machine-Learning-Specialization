{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 📌 **Understanding Multiple Linear Regression:**\n",
    "\n",
    "#### 🌟 **Step 1: What is Linear Regression?**\n",
    "\n",
    "In the last week, we learned about **linear regression**, which is used to predict a value using one variable. For example, we predicted the price of a house using **only** the size of the house.  \n",
    "The equation was:\n",
    "\n",
    "$$\n",
    "f_{w,b}(x) = w \\cdot x + b\n",
    "$$\n",
    "\n",
    "Here:  \n",
    "✅ **$ x $** = size of the house (input variable)  \n",
    "✅ **$ w $** = weight (how much the size affects the price)  \n",
    "✅ **$ b $** = bias (starting price of a house)\n",
    "\n",
    "This was **simple linear regression** because we had **only one feature**.\n",
    "\n",
    "<div style=\"text-align:center;\">     <img src=\"https://user-images.githubusercontent.com/7065401/52071924-c003ad80-2562-11e9-8297-1c6595f8a7ff.png\" alt=\"green-divider\"> </div>\n",
    "\n",
    "#### 🔥 **Step 2: What if We Have More variables?**\n",
    "\n",
    "Let's say we want to predict house prices more accurately. We now have **4 variables**:\n",
    "\n",
    "1️⃣ **$ X_1 $** = Size of the house (sq ft)  \n",
    "2️⃣ **$ X_2 $** = Number of bedrooms  \n",
    "3️⃣ **$ X_3 $** = Number of floors  \n",
    "4️⃣ **$ X_4 $** = Age of the house (years old)\n",
    "\n",
    "With more variables, our equation changes to:\n",
    "\n",
    "$$\n",
    "f_{w,b}(x) = w_1 X_1 + w_2 X_2 + w_3 X_3 + w_4 X_4 + b\n",
    "$$\n",
    "\n",
    "Now, instead of just size, we use **more details** about the house to make better predictions! 🎯\n",
    "\n",
    "For example, if we use:  \n",
    "✅ $ X_1 = 1416 $ (size)  \n",
    "✅ $ X_2 = 3 $ (bedrooms)  \n",
    "✅ $ X_3 = 2 $ (floors)  \n",
    "✅ $ X_4 = 40 $ (age)\n",
    "\n",
    "Then the price will be calculated as:\n",
    "\n",
    "$$\n",
    "\\hat{y} = 0.1(1416) + 4(3) + 10(2) - 2(40) + 80\n",
    "$$\n",
    "\n",
    "$$\n",
    "= 141.6 + 12 + 20 - 80 + 80\n",
    "$$\n",
    "\n",
    "$$\n",
    "= 173.6 \\text{ (in thousands of dollars, meaning \\$173,600)}\n",
    "$$\n",
    "\n",
    "🚀 This is called **multiple linear regression** because we use multiple variables to predict the price!\n",
    "\n",
    "<div style=\"text-align:center;\">     <img src=\"https://user-images.githubusercontent.com/7065401/52071924-c003ad80-2562-11e9-8297-1c6595f8a7ff.png\" alt=\"green-divider\"> </div>\n",
    "\n",
    "#### 🤔 **Step 3: Understanding Notation**\n",
    "\n",
    "We introduce **new notations** to keep things clean:\n",
    "\n",
    "✅ **$ X_j $** → $ j^{th} $ feature [A general way to refer to any feature (e.g., $ X_1, X_2 $ etc.)]  \n",
    "✅ **$ n $** → Number of variables  \n",
    "✅ **$ \\vec{X}^{(i)} $** → variables of $ i^{th} $ training example (e.g., the second house’s variables) **_[This is represented by row vector]_**  \n",
    "✅ **$ X^{(i)}\\_j $** → The $ j^{th} $ feature of the $ i^{th} $ house\n",
    "\n",
    "Example:  \n",
    "👉 $ X^{(2)}\\_3 = 2 $ → This means that for the **2nd house**, the **3rd feature** (number of floors) is **2**.\n",
    "\n",
    "<div style=\"text-align:center;\">     <img src=\"https://user-images.githubusercontent.com/7065401/52071924-c003ad80-2562-11e9-8297-1c6595f8a7ff.png\" alt=\"green-divider\"> </div>\n",
    "\n",
    "#### 🎯 **Step 4: Using Vectors to Simplify Equations**\n",
    "\n",
    "Instead of writing out long equations, we use **vectors** (a fancy word for a list of numbers):\n",
    "\n",
    "##### 🔹 **Weight Vector ($ W $)**\n",
    "\n",
    "$$\n",
    "\\vec{W} = [w_1, w_2, w_3, ..., w_n]\n",
    "$$\n",
    "\n",
    "👉 A list of all weights for each feature\n",
    "\n",
    "##### 🔹 **Feature Vector ($ X $)**\n",
    "\n",
    "$$\n",
    "\\vec{X} = [X_1, X_2, X_3, ..., X_n]\n",
    "$$\n",
    "\n",
    "👉 A list of all feature values\n",
    "\n",
    "Now, the equation becomes:\n",
    "\n",
    "$$\n",
    "f_{\\vec{w},b}(\\vec{x}) = \\vec{W} \\cdot \\vec{X} + b\n",
    "$$\n",
    "\n",
    "📌 The **dot (·)** means **dot product**, which is just multiplying corresponding values and summing them up!\n",
    "\n",
    "$$\n",
    "\\vec{W} \\cdot \\vec{X} = w_1X_1 + w_2X_2 + w_3X_3 + ... + w_nX_n\n",
    "$$\n",
    "\n",
    "💡 **This notation makes calculations faster and cleaner!**\n",
    "\n",
    "<div style=\"text-align:center;\">     <img src=\"https://user-images.githubusercontent.com/7065401/52071924-c003ad80-2562-11e9-8297-1c6595f8a7ff.png\" alt=\"green-divider\"> </div>\n",
    "\n",
    "#### ✨ **Summary**\n",
    "\n",
    "✅ **Simple Linear Regression** → Uses **one feature** to predict output.  \n",
    "✅ **Multiple Linear Regression** → Uses **multiple variables** for better accuracy.  \n",
    "✅ **Vector Notation** → Simplifies equations and makes computations faster.  \n",
    "✅ **Dot Product** → A mathematical trick to multiply and sum values efficiently.\n",
    "\n",
    "🚀 In the next lesson, we’ll learn about **vectorization**, a technique to make computations even **faster**!\n",
    "\n",
    "<div style=\"text-align:center;\">     <img src=\"https://user-images.githubusercontent.com/7065401/52071924-c003ad80-2562-11e9-8297-1c6595f8a7ff.png\" alt=\"green-divider\"> </div>\n",
    "\n",
    "### 📖 **Interactive Notes (MCQ)**\n",
    "\n",
    "##### **Q1: What is the difference between simple and multiple linear regression?**\n",
    "\n",
    "🔘 A. Simple uses multiple variables, multiple uses only one  \n",
    "🔘 B. Simple uses one feature, multiple uses multiple variables  \n",
    "🔘 C. There is no difference  \n",
    "🔘 D. Multiple linear regression is only for deep learning\n",
    "\n",
    "##### **Q2: What does the dot product ($ \\vec{W} \\cdot \\vec{X} $) represent?**\n",
    "\n",
    "🔘 A. Adding all variables  \n",
    "🔘 B. Multiplying corresponding values and summing them  \n",
    "🔘 C. Only multiplying variables  \n",
    "🔘 D. Ignoring bias in the model\n",
    "\n",
    "##### **Q3: In the equation $ f\\_{\\vec{w},b}(\\vec{x}) = \\vec{W} \\cdot \\vec{X} + b $, what does $ b $ represent?**\n",
    "\n",
    "🔘 A. The number of variables  \n",
    "🔘 B. The base value (bias)  \n",
    "🔘 C. A feature of the house  \n",
    "🔘 D. The weight of the largest feature\n",
    "\n",
    "##### **Q4: What is a vector?**\n",
    "\n",
    "🔘 A. A number  \n",
    "🔘 B. A list of numbers  \n",
    "🔘 C. A type of function  \n",
    "🔘 D. A machine learning model\n",
    "\n",
    "##### **Q5: Which feature might reduce the house price?**\n",
    "\n",
    "🔘 A. More square feet  \n",
    "🔘 B. More bedrooms  \n",
    "🔘 C. More floors  \n",
    "🔘 D. More age\n",
    "\n",
    "<div style=\"text-align:center;\">     <img src=\"https://user-images.githubusercontent.com/7065401/52071924-c003ad80-2562-11e9-8297-1c6595f8a7ff.png\" alt=\"green-divider\"> </div>\n",
    "\n",
    "💡 **Answers to Check:**  \n",
    "✅ Q1 → **B**  \n",
    "✅ Q2 → **B**  \n",
    "✅ Q3 → **B**  \n",
    "✅ Q4 → **B**  \n",
    "✅ Q5 → **D**\n",
    "\n",
    "🎉 That’s it! You now have a **clear** understanding of multiple linear regression! 🚀 Let’s move on to **vectorization** next!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
